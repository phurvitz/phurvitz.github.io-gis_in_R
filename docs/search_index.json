[["index.html", "Reproducible GIS analysis with R Chapter 1 Introduction", " Reproducible GIS analysis with R Phil Hurvitz 2022-03-03 00:32 Chapter 1 Introduction The materials available here were created to guide students through the CSDE workshop course on the use of geographic information systems (GIS) functionality in R, primarily with the use of the sf (Simple Features for R) package. The focus of the course is reproducible GIS analytic work flows. Please see the PowerPoint presentation introducing the workshop. Rationale GIS provides a powerful environment for the analysis of spatially-referenced data. The most widely used GIS applications in research are desktop software products with graphical user interfaces designed for interactive use. These applications (e.g., ArcMap, QGIS) are wonderful tools for exploratory data analysis and map production. However, in research they introduce the problem that much of the results of even fairly simple analytic work flows are not reproducible because the software is generally not designed to record all of the tasks the user performed. This is particularly salient during development of analytic methods, during which a substantial amount of trial-and-error occurs. Another problem with ArcGIS in particular is that geoprocessing generally requires the user to specify the output file system location and file name for any analytic results. This introduces several issues: (1) when an analyst is in the zone, taking the time do decide where to put a data set and what to call it can break the flow of creativity; (2) accepting the default location and names of geoprocessing operations can result in a jumble of data with meaningless file names; (3) given an existing data set, how would the analyst know what work flow created this as a result? Approaching GIS analysis within an R framework addresses many of these problems: Geoprocessing operations that are performed with programmatic code are reproducible. While ArcGIS and QGIS include Python for programmatic approaches, many researchers are already working with R, so only some new commands need to be learned, rather than an entire new language. R is a language that is relatively easy to read and write, lowering the bar for entry. R results are generally stored as data frames which can then be used by the many analytic functions in base R or in added packages. Geoprocessing operations produce results that are stored in memory. This will be a problem for very large data sets and/or limited RAM. On the other hand, it does not force the analyst to decide the file system location and name of a data set at run time; code can be altered to store file system outputs after work flows are determined to have created correct results. Files created using programmatic code can be traced back to the code that generated them (i.e., find / -name \"*.R\" | xargs grep \"myawesomedataset.gpkg\"). Incorporating GIS analyses in R Markdown allows the analyst to create reports that include both the analytic code used to create results as well as to show results and even maps. What this course is This course will introduce students to the use of basic GIS functionalities within the R framework. By the end of the course, students will be able to import and export GIS data sets, perform coordinate transformations, perform some rudimentary GIS analyses, and produce simple interactive maps. What this course is not This course is not intended to teach fundamentals of GIS. We assume that students have at least a beginning to intermediate level of skill in the use of a desktop GIS software application such as ArcGIS Desktop or QGIS. This is also not an R courseit is expected that students will have a fundamental grasp of the use of R. Overview Each of the topics shown below will be covered during the course. Getting started Representation of spatial features Data import/export Projections and coordinate systems Overlay analysis Point-in-polygon Polygon-on-polygon Simple interactive maps with Leaflet and mapview GitHub: gis_in_R "],["getting_started.html", "Chapter 2 Getting started 2.1 Install necessary packages 2.2 Create an RStudio project 2.3 Download files 2.4 Preview data 2.5 Save your project", " Chapter 2 Getting started Before we start, make sure that you have opened RStudio and QGIS on your computer. 2.1 Install necessary packages The most important packages We will be using for the GIS work are sf, raster, leaflet, and rgdal. To install these and others that we will be using, enter at the R console prompt (or copy-and-paste): install.packages( c(&quot;sf&quot;, &quot;raster&quot;, &quot;leaflet&quot;, &quot;rgdal&quot;, &quot;kableExtra&quot;, &quot;leaflet&quot;, &quot;dplyr&quot;, &quot;pander&quot;, &quot;knitr&quot;, &quot;kableExtra&quot;, &quot;tidycensus&quot;, &quot;ggplot2&quot;, &quot;forcats&quot;, &quot;mapview&quot;) ) This should only need to be done once on any user R installation. 2.2 Create an RStudio project Create a new RStudio project in a new folder on your desktop named r_gis (File &gt; New Project). Create a few folders Use the Files pane and create three new folders names scripts, data, and rmd. These will be used to store various files in an organized fashion. Create an R Markdown file_ Create a new R script (File &gt; New File &gt; R Markdown...) Delete most of the content And save it as r_gis.Rmd in your rmd folder. This is the file that will store the code for this workshop. In the setup chunk, add these lines for the packages we will be using: library(kableExtra) library(knitr) library(leaflet) library(pander) library(sf) library(tidycensus) library(ggplot2) library(dplyr) library(forcats) library(mapview) and then save the Rmd file. Continue adding to the file as we progress, by copying code chunks from this book to your Rmd file. 2.3 Download files Download some files into the data folder you just created: MetroKC transportation features MetroKC transit stops KC GIS medical facilities KC GIS waterbodies Esri ZIP code polygons Seattle community reporting areas After you have downloaded the files, unzip them. The most efficient way to do this is to select all the files, R-click one of them, and then select 7-Zip &gt; Extract Here. You should now have a collection of files in your data folder, including the ones you downloaded. 2.4 Preview data In QGIS, create a new project (Project &gt; New or use the keyboard shortcut Ctrl-N). Make sure the Browser panel is available (View &gt; PanelsBrowser). This will make it easier to add layers to the project. Also make sure theLayer Styling` panel is checked, which will enable you to quickly modify layer display properties. Next, make a shortcut to the data folder by R-clicking Favorites, selecting Add a Directory and navigating the the data folder. Expand all of the folders, and select the data sources you just downloaded and drag them onto the map display. If you get dialogs for Select Datum Transformations, click OK. The data set of ZIP code areas covers the entire US, so it may take some time to display them; to speed up the display process, R-click any of the King County layers and select Zoom to Layer. Alter any of the layer display properties if the colors hurt your eyes. 2.5 Save your project Save the QGIS project in a new folder named qgis; Bonus: What is the significance of the file name I used? "],["representation.html", "Chapter 3 Representation of spatial features 3.1 Points 3.2 Linestrings 3.3 Polygons 3.4 Conclusion", " Chapter 3 Representation of spatial features Vector (point, line, and polygon) features as used in the sf package are compliant with the Open Geospatial Consortium standard. To start, lets load the sf and dplyr packages . library(sf) library(dplyr) 3.1 Points Points are stored as X and Y coordinates. In the folliwing code chunk we make a sf data frame from one point at the longitude and latitude representing the Space Needle. The option crs = 4326 specifies to register the X and Y coordinates to WGS84 (EPSG code 4326). More attention will be paid to coordinate systems in Chapter 5. snxy &lt;- data.frame(name = &quot;Space Needle&quot;, x = -122.3493, y = 47.6205) space_needle &lt;- st_as_sf(snxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) We can see a complete description of the data frame, which includes the geometry type, dimension, bounding box coordinates, spatial reference ID (SRID) and proj4 projection definition, and finally the contents of the data frame, incuding the column geometry that shows the longitude and latitude. Importantly, the sf data frame is an extension of the data frame model. The data frame can consist of the same type of data you have been using in R, but with the addition of columns that contain OGC representations of vector features. print(space_needle) ## Simple feature collection with 1 feature and 1 field ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -122.3493 ymin: 47.6205 xmax: -122.3493 ymax: 47.6205 ## Geodetic CRS: WGS 84 ## name geometry ## 1 Space Needle POINT (-122.3493 47.6205) The coordinates of the point can be extracted using the st_coordinates() function: st_coordinates(space_needle) ## X Y ## 1 -122.3493 47.6205 Lets add the coordinates of Savery Hall: shxy &lt;- data.frame(name = &quot;Savery Hall&quot;, x = -122.3083, y = 47.6572) savery_hall &lt;- st_as_sf(shxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) # rbind() to put two points in one data frame pts &lt;- rbind(space_needle, savery_hall) View the data frame: print(pts) ## Simple feature collection with 2 features and 1 field ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -122.3493 ymin: 47.6205 xmax: -122.3083 ymax: 47.6572 ## Geodetic CRS: WGS 84 ## name geometry ## 1 Space Needle POINT (-122.3493 47.6205) ## 2 Savery Hall POINT (-122.3083 47.6572) View the points in coordinate space: plot(pts$geometry, axes = TRUE) 3.2 Linestrings Linestrings are linear features created a single set of ordered pairs of points. We can use the set of points we created to generate a simple linestring sf data frame with two vertices: # create a linestring sf data frame lnstr &lt;- st_sfc(st_linestring(st_coordinates(pts)), crs = 4326) As with the point data frame we can add columns: lnstr &lt;- as_tibble(lnstr) %&gt;% mutate(od = &quot;Space Needle, Savery Hall&quot;) And plot the points and linestring with base R graphics: plot(pts$geometry, axes = TRUE) text(x = st_coordinates(pts), labels = pts$name) plot(lnstr$geometry, col = 2, add = TRUE) Of course, linestrings can have any number of vertices &gt; 1. Bonus: How would you construct a set of linestrings representing distinct days of GPS data collected from one study subject? 3.3 Polygons Polygons are ordered collections of XY coordinates with at least 4 vertices. In order for the polygon to close, the first and last vertices need to be at the same XY location. Lets add another point to our collection: zooxy &lt;- data.frame(name = &quot;Woodland Park Zoo&quot;, x = -122.3543, y = 47.6685) wp_zoo &lt;- st_as_sf(zooxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) # rbind() to put two points in one data frame pts &lt;- rbind(pts, wp_zoo) And construct a polygon using the coordinates of the set of three points and closed with a ccopy of the first point (plygn &lt;- st_sfc(st_polygon(list(st_coordinates(rbind(pts, space_needle)))), crs = 4326)) ## Geometry set for 1 feature ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -122.3543 ymin: 47.6205 xmax: -122.3083 ymax: 47.6685 ## Geodetic CRS: WGS 84 ## POLYGON ((-122.3493 47.6205, -122.3083 47.6572,... Plotted with the other features: plot(plygn, col = &quot;cyan&quot;, axes = TRUE) plot(lnstr$geometry, col = 2, add = TRUE, lwd = 3) plot(pts$geometry, add = TRUE, cex = 2) text(x = st_coordinates(pts), labels = pts$name) 3.4 Conclusion It is more likely that you will be obtaining GIS data sources, rather than constructing your own using the types of functions shown above. However, understanding how these features are represented, created, and stored should give you a better understanding of how GIS works at a fundamental level. "],["import-export.html", "Chapter 4 Importing and exporting spatial data sets 4.1 Importing spatial data sets 4.2 Exporting spatial data", " Chapter 4 Importing and exporting spatial data sets 4.1 Importing spatial data sets The function st_read() is essentially wrapper to functions in the Geospatial Data Abstraction Library (GDAL), which includes translation functions for a large number of GIS data formats. For this course we will focus on the use of Esri shape files and the Open Geospatial Consortium GeoPackage (GPKG) format, although st_read() can read many different types of spatial data formats, including PostGIS database connections. We will pay particular attention to the GPKG format. Whereas a shape file can represent only a single spatial layer with a single geometric data type, a GPKG container may contain multiple objects. Also, because shape files are dependent on the dBASE tabular file format for storing attributes, there are various limitations such as 10-character uppercase column names. The underlying format for GPKG files is an SQLite database that can contain multiple different object types, including vector features tile matrix sets of imagery and raster maps at various scales attributes (non-spatial data) extensions For those familiar with Esri software, the GPKG is similar in concept to the Esri geodatabase format. However, the GPKG is open source rather than proprietary, and can be accessed directly through either GIS software that can read the format, or within an SQLite database connection for SQL operations. Lets read the ZIP code data, which are in an Esri file geodatabase. In order to read some formats it is necessary to have drivers installedtherefore not all computers can necessarily open all file types. [Was anyone not able to open the GDB?] In order to run this code chunk it will be necessary to edit the path where you downloaded the data (mydatadir). # path to the data mydatadir &lt;- &quot;H:/gis_in_r/data&quot; zippolyfname &lt;- file.path(mydatadir, &quot;zip_poly.gdb&quot;) # avoid reading over and over if(!exists(&quot;myzipcodes&quot;)){ myzipcodes &lt;- st_read(dsn = zippolyfname, layer = &quot;zip_poly&quot;, as_tibble = TRUE, geometry_column = &quot;Shape&quot;) } # change the data frame&#39;s column names to lowercase colnames(myzipcodes) &lt;- tolower(colnames(myzipcodes)) # after renaming columns it is necessary to re-establish which column contains the geometry st_geometry(myzipcodes) &lt;- &quot;shape&quot; By default, st_read() prints some metadata during the read operation (which can be silenced using quiet = TRUE). This shows that the data set contains 30924 records and 9 columns (including the geometry columns). It is has multipolygon geometry, meaning that a single record can contain multiple rings (e.g., if a single ZIP code area straddled a stream), and its spatial reference is WGS84 (coordinates as degrees of latitude and longitude). To make a manageable data set, lets extract only those ZIP codes areas for Washington State. zip_wa &lt;- myzipcodes %&gt;% dplyr::filter(state == &quot;WA&quot;) The first several records: head(zip_wa) ## Simple feature collection with 6 features and 8 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -124.0031 ymin: 46.0401 xmax: -119.2583 ymax: 49.0014 ## Geodetic CRS: WGS 84 ## # A tibble: 6 x 9 ## zip_code po_name state population pop_sqmi sqmi shape_length shape_area shape ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;MULTIPOLYGON [°]&gt; ## 1 00072 National~ WA -99 -99 1.22e3 4.20 0.386 (((-120.8514 49.00036, -120.8516~ ## 2 00073 Usdoe Ha~ WA -99 -99 3.24e2 1.63 0.0984 (((-119.4532 46.67924, -119.4554~ ## 3 00074 Yakima I~ WA -99 -99 1.35e3 4.51 0.408 (((-120.922 46.50699, -120.9216 ~ ## 4 00076 Okanogan~ WA -99 -99 7.31e2 3.83 0.232 (((-119.9193 49.00003, -119.9192~ ## 5 00195 Long Isl~ WA -99 -99 8.37e0 0.536 0.00254 (((-123.9722 46.48561, -123.972 ~ ## 6 98001 Auburn WA 35721 2003. 1.78e1 0.628 0.00549 (((-122.2269 47.34481, -122.2269~ We can now plot the ZIP code polygons. The default plot() function will create a separate graph for each variable; to only show the geometries, specify plotting only the column representing geometry. plot(x = zip_wa$shape, axes = TRUE) Lets now read the hospital shape file data. hospitals &lt;- st_read(file.path(mydatadir, &quot;medical_facilities/medical_facilities.shp&quot;)) ## Reading layer `medical_facilities&#39; from data source `H:\\gis_in_r\\data\\medical_facilities\\medical_facilities.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 154 features and 14 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 1254366 ymin: 78085.2 xmax: 1395044 ymax: 287325.1 ## Projected CRS: NAD83(HARN) / Washington North (ftUS) This shows that there were 154 rows and 15 columns. Shape files do not use EPSG codes for spatial reference, but the proj4string shows the complete unequivocal projection/coordinate system reference. Finally, lets read the water areas. h2o &lt;- st_read(file.path(mydatadir, &quot;wtrbdy/wtrbdy.shp&quot;)) ## Reading layer `wtrbdy&#39; from data source `H:\\gis_in_r\\data\\wtrbdy\\wtrbdy.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 15838 features and 16 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 607316.1 ymin: -256676.3 xmax: 1617446 ymax: 765087.4 ## Projected CRS: NAD83(HARN) / Washington North (ftUS) # type = &quot;n&quot; not to plot, but sets xlim and ylim plot(hospitals$geometry, type = &quot;n&quot;, axes = TRUE) # water plot(h2o$geometry, col = &quot;cyan&quot;, border = 0, add = TRUE) # hospital points plot(hospitals$geometry, add = TRUE) # ZIP code areas plot(zip_wa$shape, add = TRUE, col = 0, border = 1) box() Well the hospitals and water bodies seemed to plot fine. Why dont we see any ZIP code outlines as we did in QGIS? We will look at this more in Chapter 5. 4.2 Exporting spatial data Similar to st_read(), st_write() can be used to export spatial data into a variety of formats. In this exercise we will export to shape files and GPKG databases. First, we will export the Washington State ZIP code areas to a shape file. Similar to st_read(), st_write() prints an informative message. st_write(obj = zip_wa, dsn = file.path(mydatadir, &quot;zip_wa.shp&quot;)) ## Warning in abbreviate_shapefile_names(obj): Field names abbreviated for ESRI Shapefile driver ## Writing layer `zip_wa&#39; to data source `H:/gis_in_r/data/zip_wa.shp&#39; using driver `ESRI Shapefile&#39; ## Writing 547 features with 8 fields and geometry type Multi Polygon. Switch to QGIS and load the exported Washington State ZIP codes as a layer. Note that the column names were truncated to 10 characters. Also note that although the ZIP code data are stored in WGS84 latitude and longitude, they seem to overlay nicely with the hospitals, which are stores in WA State Plane north coordinates. BONUS: is this projection on the fly a good or a bad thing? What do you think I think about it? Next, we will write the first data sets we created (point, linestring, and polygon) and the WA ZIP code areas into a GPKG. st_write(obj = pts, dsn = file.path(mydatadir, &quot;r_gis.gpkg&quot;), layer = &quot;pts&quot;, append = TRUE, delete_layer = TRUE) ## Deleting layer `pts&#39; using driver `GPKG&#39; ## Updating layer `pts&#39; to data source `H:/gis_in_r/data/r_gis.gpkg&#39; using driver `GPKG&#39; ## Writing 3 features with 1 fields and geometry type Point. st_write(obj = lnstr, dsn = file.path(mydatadir, &quot;r_gis.gpkg&quot;), layer = &quot;lnstr&quot;, append = TRUE, delete_layer = TRUE) ## Deleting layer `lnstr&#39; using driver `GPKG&#39; ## Updating layer `lnstr&#39; to data source `H:/gis_in_r/data/r_gis.gpkg&#39; using driver `GPKG&#39; ## Writing 1 features with 1 fields and geometry type Line String. st_write(obj = plygn, dsn = file.path(mydatadir, &quot;r_gis.gpkg&quot;), layer = &quot;plygn&quot;, append = TRUE, delete_layer = TRUE) ## Deleting layer `plygn&#39; using driver `GPKG&#39; ## Updating layer `plygn&#39; to data source `H:/gis_in_r/data/r_gis.gpkg&#39; using driver `GPKG&#39; ## Writing 1 features with 0 fields and geometry type Polygon. st_write(obj = zip_wa, dsn = file.path(mydatadir, &quot;r_gis.gpkg&quot;), layer = &quot;zip_wa&quot;, append = TRUE, delete_layer = TRUE) ## Deleting layer `zip_wa&#39; using driver `GPKG&#39; ## Updating layer `zip_wa&#39; to data source `H:/gis_in_r/data/r_gis.gpkg&#39; using driver `GPKG&#39; ## Writing 547 features with 8 fields and geometry type Multi Polygon. Finally, add these data sets to your QGIS Map. "],["crs.html", "Chapter 5 Handling projections and coordinate systems 5.1 Projections and coordinate systems 5.2 On-the-fly projection in desktop GIS 5.3 Defining a data sets coordinate reference system 5.4 Coordinate transformation", " Chapter 5 Handling projections and coordinate systems 5.1 Projections and coordinate systems Even well-seasoned GIS analysts can stumble over projections and coordinate systems. A projection is simply a mathematical function for transforming the X and Y coordinates of a point in one spatial reference framework to X and Y coordinates in a different spatial reference framework. Initially, any point on the earth can have its location specified by the degrees north or south of the equator (latitude) and west or east of the Greenwich meridian (longitude). These spherical coordinates can be transformed to Cartesian coordinates using tried and true projection transformation equations. For the geodesically inclined, see Snyders comprehensive work, Map ProjectionsA working Manual. For example, the Space Needle shows up in Google Maps at (-122.349276°, 47.620517°) The same location on the USGS topographic sheet indicates tick marks for both UTM and State Plane coordinates. For the same location on the earths surface, the WA State Plane North HARN coordinates are (1266575.4, 230021.7) ft, and the UTM Zone 10 N coordinates are (548894.1, 5274326.9) m. BONUS Why would you use a Cartesian projected coordinate reference system versus a geographic (latitude/longitude) reference system? 5.2 On-the-fly projection in desktop GIS How is it that we could not see the ZIP code outlines in our R map (Chapter @(export)) when they appeared just fine in QGIS? Desktop GIS applications including ArcMap and QGIS employ on-the-fly projection. The software will read any existing coordinate reference system (CRS) tags associated with a data set (e.g., a .prj file as part of a shape file or a world file accompanying a TIFF or JPEG file). The software will transform the coordinates of the data to match the CRS of other data in the same map viewer. This process does not alter data in any way, but rather just changes display properties. On-the-fly projection for mapping is highly convenient, particularly if you have many different data sets that originated from different agencies, each of which uses a different CRS standard. For example, some products from the USGS are referenced to latitude/longitude and some are referenced to UTM; the City of Seattle and King County uses WA State Plane North and the Washington State Departments of Transportation and Natural Resources uses WA State Plane South. However, there is a dark side. Although the layers appear to register correctly, any analyses performed between layers will not produce correct results. This is because the geoprocessing algorithms use the absolute numerical values of the coordinates as if they were drawn on a sheet of graph paper, without respect to whether those coordinates represent any particular CRS. For this reason, any for project involving GIS analysis using multiple data sources, the first step should be to decide on a single CRS and transform all data as necessary to be stored in that CRS. Which CRS to use will depend on which distortion you want to minimize: area, shape, distance, or direction. See the USGS Map Projections poster for details, which are beyond the scope of this workshop. 5.3 Defining a data sets coordinate reference system If you have a sf spatial data frame consisting of vector data or a raster data set (covered in Chapter @(raster)) that is not tagged with its CRS, there are simple commands to do so: st_crs() for sf data frames and crs() for rasters. The function can be used to show the current CRS or to (re)define the CRS. The CRS can be specified in one of two ways, using EPSG codes, which uses numerical codes for different CRSs, or a prj4 string, which verbosely lists all the parameters for a given CRS. Using EPSG codes is more convenient than using prj4 strings. If you obtain a spatial data set, one of the things you need to be absolutely certain of is its CRS. Most data sets are provided with either files (e.g., .prj files for shape files) or internal metadata (e.g., embedded in a GeoTIFF), or at least a description of their CRS. If you do not know the CRS of your data, you can make educated guesses. In any case if you have a data set that has no CRS defined, although it may not be absolutely necessary, you should define its CRS in order to follow best practices. Lets redo the exercise from Chapter @(points) in which we created the Space Needle point, but not include the CRS: snxy &lt;- data.frame(name = &quot;Space Needle&quot;, x = -122.3493, y = 47.6205) space_needle &lt;- st_as_sf(snxy, coords = c(&quot;x&quot;, &quot;y&quot;)) When we look at its CRS, it shows NA: st_crs(space_needle) ## Coordinate Reference System: NA Because we knew in advance that these coordinates were stored in WGS84 (EPSG 4326), we can now set the data frames CRS: st_crs(space_needle) &lt;- 4326 st_crs(space_needle) ## Coordinate Reference System: ## User input: EPSG:4326 ## wkt: ## GEOGCRS[&quot;WGS 84&quot;, ## DATUM[&quot;World Geodetic System 1984&quot;, ## ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;geodetic latitude (Lat)&quot;,north, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;geodetic longitude (Lon)&quot;,east, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## USAGE[ ## SCOPE[&quot;Horizontal component of 3D system.&quot;], ## AREA[&quot;World.&quot;], ## BBOX[-90,-180,90,180]], ## ID[&quot;EPSG&quot;,4326]] Note that setting the data frames CRS does not change any coordinate XY values, it is only metadata. If you want a list of EPSG codes and their descriptions and proj4 values, use the rgdal packages make_EPSG function. For example what if we wanted the EPSG code for UTM Zone 10 N  epsg &lt;- make_EPSG() utm10 &lt;- epsg[grep(&quot;UTM.*10&quot;, epsg$note),] kable(utm10) %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F, position = &quot;left&quot;) code note prj4 prj_method 2099 26710 NAD27 / UTM zone 10N +proj=utm +zone=10 +datum=NAD27 +units=m +no_defs +type=crs Transverse Mercator 2267 26910 NAD83 / UTM zone 10N +proj=utm +zone=10 +datum=NAD83 +units=m +no_defs +type=crs Transverse Mercator 3109 3157 NAD83(CSRS) / UTM zone 10N +proj=utm +zone=10 +ellps=GRS80 +units=m +no_defs +type=crs Transverse Mercator 3376 32210 WGS 72 / UTM zone 10N +proj=utm +zone=10 +ellps=WGS72 +units=m +no_defs +type=crs Transverse Mercator 3446 32310 WGS 72 / UTM zone 10S +proj=utm +zone=10 +south +ellps=WGS72 +units=m +no_defs +type=crs Transverse Mercator 3516 32410 WGS 72BE / UTM zone 10N +proj=utm +zone=10 +ellps=WGS72 +units=m +no_defs +type=crs Transverse Mercator 3586 32510 WGS 72BE / UTM zone 10S +proj=utm +zone=10 +south +ellps=WGS72 +units=m +no_defs +type=crs Transverse Mercator 3657 32610 WGS 84 / UTM zone 10N +proj=utm +zone=10 +datum=WGS84 +units=m +no_defs +type=crs Transverse Mercator 3735 32710 WGS 84 / UTM zone 10S +proj=utm +zone=10 +south +datum=WGS84 +units=m +no_defs +type=crs Transverse Mercator 4233 3717 NAD83(NSRS2007) / UTM zone 10N +proj=utm +zone=10 +ellps=GRS80 +units=m +no_defs +type=crs Transverse Mercator 4256 3740 NAD83(HARN) / UTM zone 10N +proj=utm +zone=10 +ellps=GRS80 +units=m +no_defs +type=crs Transverse Mercator 5062 6339 NAD83(2011) / UTM zone 10N +proj=utm +zone=10 +ellps=GRS80 +units=m +no_defs +type=crs Transverse Mercator 6530 6653 NAD83(CSRS) / UTM zone 10N + CGVD2013 height +proj=utm +zone=10 +ellps=GRS80 +units=m +vunits=m +no_defs +type=crs (null)  or if we wanted to find out what EPSG code 2927 is: kable(epsg %&gt;%filter(code == 2927)) %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F, position = &quot;left&quot;) code note prj4 prj_method 2927 NAD83(HARN) / Washington South (ftUS) +proj=lcc +lat_0=45.3333333333333 +lon_0=-120.5 +lat_1=47.3333333333333 +lat_2=45.8333333333333 +x_0=500000.0001016 +y_0=0 +ellps=GRS80 +units=us-ft +no_defs +type=crs Lambert Conic Conformal (2SP) 5.4 Coordinate transformation If you have a data set stored in one CRS and you want to transform its coordinates to match another CRS, use st_transform() for sf data frames or the projctRaster() function for raster data sets. Here we will make a new Space Needle point stored with UTM 10 NAD83. Note the changed coordinates shown in the geometry column. (space_needle_utm10 &lt;- space_needle %&gt;% st_transform(26910)) ## Simple feature collection with 1 feature and 1 field ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 548894.1 ymin: 5274327 xmax: 548894.1 ymax: 5274327 ## Projected CRS: NAD83 / UTM zone 10N ## name geometry ## 1 Space Needle POINT (548894.1 5274327) Or if you want to overwrite the data of an existing data frame with a new CRS: (space_needle &lt;- space_needle %&gt;% st_transform(26910)) ## Simple feature collection with 1 feature and 1 field ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 548894.1 ymin: 5274327 xmax: 548894.1 ymax: 5274327 ## Projected CRS: NAD83 / UTM zone 10N ## name geometry ## 1 Space Needle POINT (548894.1 5274327) which should be done with care because it alters the values of an existing data set. "],["geoprocessing.html", "Chapter 6 Geoprocessing 6.1 Buffering 6.2 Point-in-polygon 6.3 Polygon-on-polygon", " Chapter 6 Geoprocessing Make sure that mydatadir points to the location where the GIS data files were downloaded and unzipped. mydatadir &lt;- &quot;H:/gis_in_r/data&quot; 6.1 Buffering Buffering is one of the most common geoprocessing techniques. sf provides the st_buffer() command to create Euclidean buffers around vector features. Lets create 1 km buffers around the points we created earlier. For this process, first we transform the points to UTM 10 so when we specify a buffer distance of 1,000 that translates to 1 km, and finally we transform to WA State Plane N. # create the points snxy &lt;- data.frame(name = &quot;Space Needle&quot;, x = -122.3493, y = 47.6205) space_needle &lt;- st_as_sf(snxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) shxy &lt;- data.frame(name = &quot;Savery Hall&quot;, x = -122.3083, y = 47.6572) savery_hall &lt;- st_as_sf(shxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) zooxy &lt;- data.frame(name = &quot;Woodland Park Zoo&quot;, x = -122.3543, y = 47.6685) wp_zoo &lt;- st_as_sf(zooxy, coords = c(&quot;x&quot;, &quot;y&quot;), crs = 4326) pts &lt;- rbind(space_needle, savery_hall, wp_zoo) # make the buffer with inline transforms pts_buf_1km &lt;- pts %&gt;% st_transform(26910) %&gt;% st_buffer(dist = 1000) %&gt;% st_transform(2926) Export the point buffers to our GPKG: # write to the GPKG mygpkg &lt;- file.path(mydatadir, &quot;r_gis.gpkg&quot;) st_write(obj = pts_buf_1km, dsn = mygpkg, layer = &quot;pts_buf_1km&quot;, quiet = TRUE, append = TRUE, delete_layer = TRUE) We will also make 500 ft buffers around the freeways of King County and export them to the GPKG if(! exists(&quot;kctrans&quot;)){ kctrans &lt;- st_read( file.path(mydatadir, &quot;Metro_Transportation_Network_TNET_in_King_County__trans_network_line.shp&quot;), quiet = TRUE) } # freeways are KC_FCC_ID = F kcfwy &lt;- kctrans %&gt;% filter(KC_FCC_ID == &quot;F&quot;) # buffer kcfwy_buf_500ft &lt;- kcfwy %&gt;% st_transform(2926) %&gt;% st_buffer(500) # write to the GPKG mygpkg &lt;- file.path(mydatadir, &quot;r_gis.gpkg&quot;) st_write(obj = kcfwy_buf_500ft, dsn = mygpkg, layer = &quot;kcfwy_buf_500ft&quot;, quiet = TRUE, update = TRUE) ## Warning: &#39;update&#39; is deprecated. ## Use &#39;append&#39; instead. ## See help(&quot;Deprecated&quot;) What the !#*$&amp;? Why are there all those little tiny buffers around the freeway lines? To be addressed below. 6.2 Point-in-polygon For the next analysis, we will tabulate the density of transit stops in each census block group and then look for patterns in transit stop density by median household income. First we need to get the census block groups and median family income using tidycensus. Covering the use of tidycensus is beyond the scope of this workshop; for an introduction, see the Computational Demography seminar presented by Connor Gilroy and Neal Marquez. Using pipes in magrittr, we perform an inline CRS transformation to WA State Plane N and also calculate the area of each bloc group (which we will need for the density measurement later). If you did not get your census API key, you will need to load the layer from the census.gpkg file: acs5_2018_bg &lt;- st_read(dsn = file.path(mydatadir, &quot;census.gpkg&quot;), layer = &quot;acs5_2018_bg&quot;, quiet = TRUE) st_crs(acs5_2018_bg) &lt;- 2926 # cache data options(tigris_use_cache = TRUE) # where to store data tigris_cache_dir &lt;- mydatadir # if you have your API key, enter it here rather than using the system environment variable # myapikey &lt;- &quot;foobar&quot; myapikey &lt;- Sys.getenv(&quot;CENSUS_API_KEY&quot;) census_api_key(myapikey) ## To install your API key for use in future sessions, run this function with `install = TRUE`. # get the data and project it to match the bus stops, also calculate the area acs5_2018_bg &lt;- get_acs( geography = &quot;block group&quot;, variables = c(medfamincome=&quot;B19113_001&quot;), state = &quot;WA&quot;, county = &quot;King&quot;, geometry = TRUE, moe = 95, cache_table = TRUE, output = &quot;wide&quot;) %&gt;% st_transform(2926) %&gt;% mutate(area_ft = as.numeric(st_area(.))) ## Getting data from the 2015-2019 5-year ACS ## Using FIPS code &#39;53&#39; for state &#39;WA&#39; ## Using FIPS code &#39;033&#39; for &#39;King County&#39; colnames(acs5_2018_bg) &lt;- tolower(colnames(acs5_2018_bg)) Quickly view the data in a ggplot(): acs5_2018_bg %&gt;% ggplot() + geom_sf(aes(fill = medfamincomee), size = .25) + scale_fill_viridis_c() + theme_void() Load the bus stops: busstop &lt;- st_read( file.path(mydatadir, &quot;busstop/busstop.shp&quot;), quiet = TRUE) st_crs(busstop) &lt;- 2926 ## Warning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for that colnames(busstop) &lt;- tolower(colnames(busstop)) First, lets look at the column names in busstop: print(colnames(busstop)) ## [1] &quot;objectid&quot; &quot;busstop_id&quot; &quot;zonekey&quot; &quot;begin_date&quot; &quot;end_date&quot; &quot;tlink_id&quot; &quot;ramkey&quot; &quot;access_lvl&quot; ## [9] &quot;landing_pd&quot; &quot;trnsfr_pt&quot; &quot;authority&quot; &quot;awning&quot; &quot;bearing_cd&quot; &quot;curb&quot; &quot;curb_ht&quot; &quot;bay&quot; ## [17] &quot;bike_rack&quot; &quot;created_by&quot; &quot;cross_stre&quot; &quot;curb_paint&quot; &quot;dt_created&quot; &quot;dt_mapped&quot; &quot;dt_mod&quot; &quot;displacemt&quot; ## [25] &quot;rampositio&quot; &quot;ditch&quot; &quot;ext_surfc&quot; &quot;ext_width&quot; &quot;frm_cross&quot; &quot;frm_intrst&quot; &quot;juris&quot; &quot;reg_fare&quot; ## [33] &quot;rfp_dist&quot; &quot;zip_code&quot; &quot;i_sgn_anch&quot; &quot;i_sgn&quot; &quot;int_loc&quot; &quot;link_len&quot; &quot;pcnt_from&quot; &quot;t_nd_from&quot; ## [41] &quot;mod_by&quot; &quot;news_box&quot; &quot;non_mt_sgn&quot; &quot;bollards&quot; &quot;num_shelt&quot; &quot;on_street&quot; &quot;othr_cov_a&quot; &quot;owner&quot; ## [49] &quot;paint_len&quot; &quot;pk_stp_sur&quot; &quot;pullout&quot; &quot;ret_wall&quot; &quot;rfa_flag&quot; &quot;rt_sgn_tp&quot; &quot;sched_hold&quot; &quot;shdr_surf&quot; ## [57] &quot;shdr_width&quot; &quot;side&quot; &quot;side_cross&quot; &quot;side_on&quot; &quot;swlk_width&quot; &quot;sgn_mt_dir&quot; &quot;sgn_pst_an&quot; &quot;sgn_pst_tp&quot; ## [65] &quot;spc_sgn_tp&quot; &quot;length&quot; &quot;status&quot; &quot;stop_type&quot; &quot;address&quot; &quot;add_commnt&quot; &quot;strp_width&quot; &quot;t_signal&quot; ## [73] &quot;wlk_surf&quot; &quot;xcoord&quot; &quot;ycoord&quot; &quot;xcoord_off&quot; &quot;ycoord_off&quot; &quot;geometry&quot; To get the census data as an attribute on each transit stop, use st_join(): busstop &lt;- busstop %&gt;% st_join(acs5_2018_bg) We now see that there are additional variables, particularly medfamincomee: print(colnames(busstop)) ## [1] &quot;objectid&quot; &quot;busstop_id&quot; &quot;zonekey&quot; &quot;begin_date&quot; &quot;end_date&quot; &quot;tlink_id&quot; ## [7] &quot;ramkey&quot; &quot;access_lvl&quot; &quot;landing_pd&quot; &quot;trnsfr_pt&quot; &quot;authority&quot; &quot;awning&quot; ## [13] &quot;bearing_cd&quot; &quot;curb&quot; &quot;curb_ht&quot; &quot;bay&quot; &quot;bike_rack&quot; &quot;created_by&quot; ## [19] &quot;cross_stre&quot; &quot;curb_paint&quot; &quot;dt_created&quot; &quot;dt_mapped&quot; &quot;dt_mod&quot; &quot;displacemt&quot; ## [25] &quot;rampositio&quot; &quot;ditch&quot; &quot;ext_surfc&quot; &quot;ext_width&quot; &quot;frm_cross&quot; &quot;frm_intrst&quot; ## [31] &quot;juris&quot; &quot;reg_fare&quot; &quot;rfp_dist&quot; &quot;zip_code&quot; &quot;i_sgn_anch&quot; &quot;i_sgn&quot; ## [37] &quot;int_loc&quot; &quot;link_len&quot; &quot;pcnt_from&quot; &quot;t_nd_from&quot; &quot;mod_by&quot; &quot;news_box&quot; ## [43] &quot;non_mt_sgn&quot; &quot;bollards&quot; &quot;num_shelt&quot; &quot;on_street&quot; &quot;othr_cov_a&quot; &quot;owner&quot; ## [49] &quot;paint_len&quot; &quot;pk_stp_sur&quot; &quot;pullout&quot; &quot;ret_wall&quot; &quot;rfa_flag&quot; &quot;rt_sgn_tp&quot; ## [55] &quot;sched_hold&quot; &quot;shdr_surf&quot; &quot;shdr_width&quot; &quot;side&quot; &quot;side_cross&quot; &quot;side_on&quot; ## [61] &quot;swlk_width&quot; &quot;sgn_mt_dir&quot; &quot;sgn_pst_an&quot; &quot;sgn_pst_tp&quot; &quot;spc_sgn_tp&quot; &quot;length&quot; ## [67] &quot;status&quot; &quot;stop_type&quot; &quot;address&quot; &quot;add_commnt&quot; &quot;strp_width&quot; &quot;t_signal&quot; ## [73] &quot;wlk_surf&quot; &quot;xcoord&quot; &quot;ycoord&quot; &quot;xcoord_off&quot; &quot;ycoord_off&quot; &quot;geoid&quot; ## [79] &quot;name&quot; &quot;medfamincomee&quot; &quot;medfamincomem&quot; &quot;area_ft&quot; &quot;geometry&quot; To calculate density we need a total count of transit stops by census unit id (GEOID) as well as the area. Note because all variables are identical within each census units, we can use medfamincomee = min(medfamincomee) in the summarize function. # tabulate the count of transit stops nbusstop &lt;- busstop %&gt;% group_by(geoid) %&gt;% summarise(n_busstop = n(), density_ha = n() / min(area_ft) * 107639 , medfamincomee = min(medfamincomee)) Lets make a scatter plot with a regression line and error. nbusstop %&gt;% ggplot(aes(x = medfamincomee, y = density_ha)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + xlab(&quot;block group median family income, ACS-5, 2018&quot;) + ylab(&quot;transit stop density per ha&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 78 rows containing non-finite values (stat_smooth). ## Warning: Removed 78 rows containing missing values (geom_point). Looks like no relationship exists. How about some formal statistics? pander( summary( lm(data = nbusstop, medfamincomee ~ density_ha)))   Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 126067 2017 62.51 0 density_ha 4414 11473 0.3848 0.7005 Fitting linear model: medfamincomee ~ density_ha Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 1186 51827 0.000125 -0.0007195 6.3 Polygon-on-polygon 6.3.1 Intersect For the next exercise we will estimate the proportion of persons living below the federal poverty level within Seattle neighborhoods using 2018 ACS data at the tract level (poverty data are not available at the block group level). First we will load the city neighborhood boundaries, including a CRS transformation to WA State Plane N: nhood &lt;- st_read( file.path(mydatadir, &quot;Community_Reporting_Areas.shp&quot;), quiet = TRUE) %&gt;% st_transform(2926) names(nhood) = tolower(names(nhood)) Get the tract data for the total count of persons for whom poverty status was determined and the count of persons living below the poverty level, also transforming to WA State Plane N and calculating the area of the tract. If you did not get your census API key, you will need to load the layer from the census.gpkg file: acs5_2018_trt &lt;- st_read(dsn = file.path(mydatadir, &quot;census.gpkg&quot;), layer = &quot;acs5_2018_trt&quot;, quiet = TRUE) st_crs(acs5_2018_trt) &lt;- 2926 # get the data and project it to match the bus stops, also calculate the area acs5_2018_trt &lt;- get_acs( year = 2018, geography = &quot;tract&quot;, variables = c(n=&quot;B06012_001&quot;, n_pov=&quot;B06012_002&quot;), state = &quot;WA&quot;, county = &quot;King&quot;, geometry = TRUE, moe = 95, cache_table = TRUE, output = &quot;wide&quot;) %&gt;% st_transform(2926) %&gt;% mutate(area_ft_tract = as.numeric(st_area(.))) colnames(acs5_2018_trt) &lt;- tolower(colnames(acs5_2018_trt)) Intersecting the tracts and neighborhoods will produce a polygon data set with data only for the area in common between both data sets. It will also subdivide polygons wherever there is an overlap between polygons from the different input layers. We also calculate the area of the resultant polygons (slivers) for estimating person counts within each sliver using area weighting under the (arguably incorrect) assumption that the population is uniformly distributed across the tract. The estimate of the count of persons within each sliver is calculated as \\[pop_{sliver} = pop_{tract} \\times \\frac{area_{sliver}}{area_{original}}\\] nhood_trt &lt;- st_intersection(x = nhood, acs5_2018_trt) %&gt;% mutate(area_ft_intersect = as.numeric(st_area(.)), n_est = ne * as.numeric(st_area(.)) / area_ft_tract, n_est_pov = n_pove * as.numeric(st_area(.)) / area_ft_tract) ## Warning: attribute variables are assumed to be spatially constant throughout all geometries We then sum the area-weighted counts for each neighborhood: \\[\\sum_{i=1}^{n} pop_{sliver}\\] where \\(i\\) is the sliver, \\(n\\) is the count of slivers, and \\(pop_{sliver}\\) is the estimated population of the sliver. This aggregation to the neighborhood level using the estimated counts of the number of persons and the number of persons living below poverty is done with group_by() and summarize() nhood_pov &lt;- nhood_trt %&gt;% group_by(gen_alias) %&gt;% summarize( neighdist = first(neighdist), n = sum(n_est), n_pov = sum(n_est_pov), pct_pov = round(sum(n_est_pov) / sum(n_est) * 100, 1)) Lets make a quick plot: nhood_pov %&gt;% ggplot() + geom_sf(aes(fill = pct_pov), size = .25) + scale_fill_viridis_c() + theme_void() nhood_pov %&gt;% ggplot(aes(x = reorder(gen_alias, pct_pov), y=pct_pov)) + geom_bar(stat = &quot;identity&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + xlab(&quot;neighborhood&quot;) + ylab(&quot;% living under\\nfederal poverty level&quot;) Starving students? We can also export this for mapping in QGIS: st_write(obj = nhood_pov, dsn = mygpkg, layer = &quot;nhood_pov&quot;, quiet = TRUE, update = TRUE, delete_layer = TRUE) ## Warning: &#39;update&#39; is deprecated. ## Use &#39;append&#39; instead. ## See help(&quot;Deprecated&quot;) Here shown with quintiles: 6.3.2 Union st_union() will make a single geometry from multiple geometries. We can use this to dissolve the freeway buffers we created before. Lets pipe together the st_union() and st_write() to dissolve the buffers and write to the GPKG in one step. st_write(obj = st_union(kcfwy_buf_500ft), dsn = mygpkg, layer = &quot;kcfwy_buf_500ft_union&quot;, quiet = TRUE, update = TRUE) ## Warning: &#39;update&#39; is deprecated. ## Use &#39;append&#39; instead. ## See help(&quot;Deprecated&quot;) Verify in QGIS: We can also dissolve based on a variable. In this example we are grouping by the neighdist variable, which represents the larger neighborhood districts, and summing the count of persons and the count of persons below the poverty level as well as calculating the percent below poverty. sf is doing a geometric st_union() behind the scenes. # summarize == union districts &lt;- nhood_pov %&gt;% group_by(neighdist) %&gt;% summarise( n = sum(n), n_pov = sum(n_pov), pct_pov = round(sum(n_pov) / sum(n) * 100, 1)) # save st_write(obj = districts, dsn = mygpkg, layer = &quot;districts&quot;, quiet = TRUE, update = TRUE, delete_layer = TRUE) ## Warning: &#39;update&#39; is deprecated. ## Use &#39;append&#39; instead. ## See help(&quot;Deprecated&quot;) Here the dissolved layer is shown in QGIS using poverty percent quintiles. "],["leaflet.html", "Chapter 7 leaflet and mapview maps", " Chapter 7 leaflet and mapview maps This exercise will introduce construction of a Leaflet map using the leaflet package. Also simple interface uses the mapview::mapview() function, which automatically adds the OpenStreetMap background, uses pre-loaded colors, and with the legend = TRUE option also adds a map legend. mapview(nhood_pov, zcol = &quot;pct_pov&quot;, legend = TRUE) We will now build up a map using leaflet() for a bit more control. # CRS nhood_pov_4326 &lt;- nhood_pov %&gt;% st_transform(4326) # make a label with the count of persons, persons below poverty, and % poverty nhood_pov_4326$mylab &lt;- sprintf(&quot;n_pov=%s&lt;br&gt;n=%s&lt;br&gt;%s&lt;br&gt;&quot;, round(nhood_pov_4326$n_pov, 0), round(nhood_pov_4326$n, 0), paste(&quot;pov=&quot;, nhood_pov_4326$pct_pov, &quot;%&quot;, sep=&quot;&quot;)) l &lt;- leaflet(data = nhood_pov_4326) %&gt;% addPolygons(popup = ~mylab, weight = 2) %&gt;% addTiles() l Lets change the labels to include neighborhood name and % poverty, add choropleth fill and a legend: # CRS nhood_pov_4326 &lt;- nhood_pov %&gt;% st_transform(4326) mypalette &lt;- colorQuantile(palette = &quot;viridis&quot;, domain = nhood_pov_4326$pct_pov, n = 4) # make a label with the count of persons, persons below poverty, and % poverty nhood_pov_4326$mylab &lt;- sprintf(&quot;%s&lt;br&gt;%s&lt;br&gt;&quot;, nhood_pov_4326$gen_alias, paste(&quot;pov=&quot;, nhood_pov_4326$pct_pov, &quot;%&quot;, sep=&quot;&quot;)) l &lt;- leaflet(data = nhood_pov_4326) %&gt;% addPolygons(popup = ~mylab, weight = 2, fillColor = ~mypalette(pct_pov), opacity = 0.7) %&gt;% addTiles() %&gt;% addLegend(pal=mypalette, values=~pct_pov, opacity=0.7, title = &quot;% below poverty&quot;, position = &quot;bottomleft&quot; ) l Finally, add the hospitals with a label that will display when hovering over the point marker. # CRS nhood_pov_4326 &lt;- nhood_pov %&gt;% st_transform(4326) # hospitals hospitals &lt;- st_read(file.path(mydatadir, &quot;medical_facilities&quot;, &quot;medical_facilities.shp&quot;), quiet = TRUE) %&gt;% st_transform(4326) mypalette &lt;- colorQuantile(palette = &quot;viridis&quot;, domain = nhood_pov_4326$pct_pov, n = 4) # make a label with the count of persons, persons below poverty, and % poverty nhood_pov_4326$mylab &lt;- sprintf(&quot;%s&lt;br&gt;%s&lt;br&gt;&quot;, nhood_pov_4326$gen_alias, paste(&quot;pov=&quot;, nhood_pov_4326$pct_pov, &quot;%&quot;, sep=&quot;&quot;)) l &lt;- leaflet(data = nhood_pov_4326) %&gt;% addPolygons(popup = ~mylab, weight = 2, fillColor = ~mypalette(pct_pov), opacity = 0.7) %&gt;% addTiles() %&gt;% addLegend(pal=mypalette, values=~pct_pov, opacity=0.7, title = &quot;% below poverty&quot;, position = &quot;bottomleft&quot; ) l &lt;- addCircleMarkers(map = l, data = hospitals, radius = 5, weight = 1, opacity = 0.9, fillOpacity = 0.5, label = ~ABB_NAME) l "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
